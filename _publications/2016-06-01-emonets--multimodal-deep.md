---
title: "Emonets: Multimodal deep learning approaches for emotion recognition in video"
collection: publications
permalink: /publication/2016-06-01-emonets--multimodal-deep
excerpt: 'Add except...'
month: june
year: 2016
date: 2016-06-01
venue: Journal on Multimodal User Interfaces
authors: Samira Ebrahimi Kahou, Xavier Bouthillier, Pascal Lamblin, Caglar Gulcehre, Vincent Michalski, Kishore Konda, Sébastien Jean, Pierre Froumenty, Yann Dauphin, Nicolas Boulanger-Lewandowski and others
paperurl: https://arxiv.org/pdf/1503.01800
type: journal
citation: ''
---

The task of the Emotion Recognition in the Wild (EmotiW) Challenge is to assign one of
seven emotions to short video clips extracted from Hollywood style movies. The videos
depict acted-out emotions under realistic conditions with a large degree of variation in
attributes such as pose and illumination, making it worthwhile to explore approaches
which consider combinations of features from multiple modalities for label assignment.
In this paper we present our approach to learning several specialist models using deep
learning techniques, each focusing on one modality. Among these are a convolutional
neural network, focusing on capturing visual information in detected faces, a deep
belief net focusing on the representation of the audio stream, a K-Means based
“bag-of-mouths” model, which extracts visual features around the mouth region and a
relational autoencoder, which addresses spatio-temporal aspects of videos. We explore
multiple methods for the combination of cues from these modalities into one common
classifier. This achieves a considerably greater accuracy than predictions from our
strongest single-modality classifier. Our method was the winning submission in the 2013
EmotiW challenge and achieved a test set accuracy of 47.67 % on the 2014 dataset.

BibTeX:

    @article{kahou2016emonets,
        author = {Kahou, Samira Ebrahimi and Bouthillier, Xavier and Lamblin, Pascal and Gulcehre, Caglar and Michalski, Vincent and Konda, Kishore and Jean, S{\'e}bastien and Froumenty, Pierre and Dauphin, Yann and Boulanger-Lewandowski, Nicolas and others},
        journal = {Journal on Multimodal User Interfaces},
        month = {june},
        number = {2},
        pages = {99--111},
        publisher = {Springer},
        title = {Emonets: Multimodal deep learning approaches for emotion recognition in video},
        url = {https://arxiv.org/pdf/1503.01800},
        volume = {10},
        year = {2016}
    }
    
    
